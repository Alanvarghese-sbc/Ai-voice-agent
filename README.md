<!-- # üéôÔ∏è AI Voice Agent ‚Äî 30 Days of AI Voice Agents (Day 13)

## üìå Project Overview
This project is part of the **30 Days of AI Voice Agents** challenge.  
It‚Äôs a **fully functional conversational AI agent** that listens to voice input, processes it using an LLM, and responds back in natural speech ‚Äî all while remembering context from previous conversations.

---

## üõ†Ô∏è Technologies Used
- **Frontend:** HTML, CSS, JavaScript
- **Backend:** Python, FastAPI
- **AI Services:**
  - Speech-to-Text (STT) ‚Äî Converts voice input to text
  - Large Language Model (LLM) ‚Äî Generates intelligent responses
  - Text-to-Speech (TTS) ‚Äî Converts AI responses back into speech
- **Datastore:** In-memory / custom datastore for chat history

---

## ‚öôÔ∏è Architecture
1. **Voice Input** ‚Üí User speaks into the microphone.
2. **STT Service** ‚Üí Audio is transcribed into text.
3. **LLM API** ‚Üí Processes user query along with previous chat history.
4. **TTS Service** ‚Üí AI-generated text response is converted to audio.
5. **UI Playback** ‚Üí Audio response is played back to the user.
6. **Loop** ‚Üí Conversation continues with remembered context.

---

## ‚ú® Features
‚úÖ Real-time voice-to-voice AI conversation  
‚úÖ Chat history to maintain conversation context  
‚úÖ Error handling with fallback responses  
‚úÖ Fully responsive, interactive UI  
‚úÖ Single-button recording system with animations  

---

## üì∏ Screenshots
*(Add screenshots here of your UI and terminal responses)*

---

## üöÄ Getting Started

### 1Ô∏è‚É£ Clone the Repository
```bash
git clone https://github.com/YOUR_USERNAME/YOUR_REPO_NAME.git
cd YOUR_REPO_NAME -->

# AI Voice Agent ‚Äì 30 Days Challenge

## Overview
This project is part of the **30 Days of AI Voice Agents** challenge.  
It is a **web-based voice assistant** that allows users to interact with an AI through voice. The application can:

- Transcribe your speech in real-time.
- Generate intelligent conversational responses using AI.
- Convert the AI's text responses into natural-sounding audio.
- Provide a seamless, interactive UI for recording, playback, and continuous conversation.

This challenge helped me explore **voice interfaces, AI APIs, and modern frontend-backend integration**.

---

## Key Features

1. **Voice-to-Text (Speech Recognition)**  
   - Users can speak to the agent.  
   - Speech is converted to text using AssemblyAI API.  

2. **Conversational AI Response**  
   - Text from user speech is sent to Gemini AI (or other LLM) for generating context-aware responses.  

3. **Text-to-Speech (TTS)**  
   - AI responses are converted to audio using Murf API.  
   - Fallback audio is played if TTS fails.  

4. **Interactive UI**  
   - Start/Stop Recording using a single toggle button.  
   - Audio playback starts automatically once the AI responds.  
   - Responsive and modern UI with animations for recording state.  

5. **Session Management**  
   - Each page load creates a unique session ID.  
   - Allows multi-turn conversations with context persistence.

---

## Technologies Used

- **Frontend:** HTML, CSS, JavaScript  
- **Backend:** Python, FastAPI  
- **APIs & Services:**  
  - **Murf API** ‚Äì Text-to-Speech  
  - **AssemblyAI API** ‚Äì Speech-to-Text  
  - **Gemini API** ‚Äì Conversational AI  
- **Other Tools:**  
  - dotenv ‚Äì Environment variable management  
  - MediaRecorder API ‚Äì Browser-side audio recording  

---

## Project Architecture

User (Browser)
‚îÇ
‚îú‚îÄ> Record Audio / Input Text
‚îÇ
Frontend (HTML, CSS, JS)
‚îÇ
‚îú‚îÄ> API Request to FastAPI
‚îÇ
Backend (FastAPI)
‚îÇ ‚îú‚îÄ> AssemblyAI ‚Üí Transcribe speech to text
‚îÇ ‚îú‚îÄ> Gemini ‚Üí Generate AI response
‚îÇ ‚îî‚îÄ> Murf ‚Üí Convert AI response to speech
‚îÇ
‚îî‚îÄ> Return transcription & audio URL to frontend


---

## Setup & Installation

### 1. Clone the repository
bash
git clone https://github.com/<username>/<repo-name>.git
cd <repo-name>

---



### 2. Create a virtual environment
bash
python -m venv venv
# Activate virtual environment
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate


### 3. Install dependencies
bash
pip install -r requirements.txt

### 4. Create .env file in project root
MURF_API_KEY=your_murf_api_key
ASSEMBLY_API_KEY=your_assemblyai_api_key
GEMINI_API_KEY=your_gemini_api_key


Important: Do not commit .env to GitHub. Ensure it‚Äôs listed in .gitignore.

5. Run the FastAPI server
uvicorn app:app --reload

6. Open the frontend

Open index.html in your browser.

Recommended browsers: Chrome or Edge for microphone support.

Screenshots

Include screenshots of your updated UI.

Capture recording button animations and audio playback.

Usage

Click the üéôÔ∏è Start Recording button to speak to the AI.

Stop recording by clicking the ‚èπÔ∏è Stop Recording button.

The AI will transcribe your speech, generate a response, and play audio automatically.

Your conversation history is displayed in the transcript box.
